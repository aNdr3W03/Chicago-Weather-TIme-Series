# -*- coding: utf-8 -*-
"""Second Project: Time Series Data ML - Chicago Weather.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12N5H4brCFj1dnn7_pUTCck1-PKBCoiV-

# Proyek Kedua: Membuat Model Machine Learning dengan Data Time Series

---

### Dicoding Submission
### Belajar Pengembangan Machine Learning

---

Kriteria submission:
- Dataset yang akan dipakai **bebas**, namun **minimal memiliki 1000 sampel**.
- Harus menggunakan `LSTM` dalam arsitektur model.
- Harus menggunakan model `sequential`.
- **Validation set** sebesar **20%** dari total dataset.
- Harus menggunakan `Learning Rate` pada `Optimizer`.
- **MAE < 10%** skala data.

---

Saran dan Tips:
- Dataset yang digunakan memiliki banyak sampel data.
- Mengimplementasikan `callback`.
- Membuat `plot loss` dan `akurasi` pada saat `training` dan `validation`.

---

- **Bintang 3** : Semua ketentuan terpenuhi namun hanya mengikuti seperti apa yang ada pada modul.
- **Bintang 4** : Semua ketentuan terpenuhi, dataset memiliki **minimal 2000** sampel data dan **MAE** dari model **< 10%** skala data.
- **Bintang 5** : Semua ketentuan terpenuhi, dataset memiliki **minimal 10000** sampel data dan **MAE** dari model **< 10%** skala data.

---

# Data Diri

Nama: Andrew Benedictus Jamesie  
E-mail: andrewbjamesie@yahoo.com  

---
---

Dataset: [(Kaggle) Chicago_Weather_2017_2022.csv](https://www.kaggle.com/datasets/leonidasliao/divvy-station-dock-capacity-time-series-forecast?select=Chicago_Weather_2017_2022.csv "Chicago Weather (2017-2022)")

Reference:

[(Dicoding) Kurang paham dengan poin evaluasi yang saya terima](https://www.dicoding.com/academies/185/discussions/144012)

[(Dicoding) Menurunkan MAE](https://www.dicoding.com/academies/185/discussions/117262)

[(Dicoding) Nilai MAE yang stuck tidak bisa turun](https://www.dicoding.com/academies/185/discussions/154348)
"""

import pandas as pd

df = pd.read_csv('drive/MyDrive/Chicago_Weather_2017_2022.csv')
df

df.isnull().sum()

import matplotlib.pyplot as plt

time = df['datetime'].values
temp = df['temp'].values

plt.figure(figsize=(12, 5))
plt.plot(time, temp)
plt.title('Chicago Average Temperature', fontsize=20)
plt.xlabel('Date')
plt.ylabel('Temperature (â„‰)')
plt.show()

from sklearn.model_selection import train_test_split

xTrain, xTest, yTrain, yTest = train_test_split(time, temp, test_size=0.2, random_state=1, shuffle=False)

print(xTrain.shape, xTest.shape)
print(yTrain.shape, yTest.shape)

import tensorflow as tf

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)

    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))

    return ds.batch(batch_size).prefetch(1)

train_set = windowed_dataset(yTrain, window_size=60, batch_size=100, shuffle_buffer=1000)
val_set   = windowed_dataset(yTest,  window_size=60, batch_size=100, shuffle_buffer=1000)

model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(60, return_sequences=True),
    tf.keras.layers.LSTM(60),
    tf.keras.layers.Dense(30, activation='relu'),
    tf.keras.layers.Dense(10, activation='relu'),
    tf.keras.layers.Dense(1)
])

model.compile(
    loss      = tf.keras.losses.Huber(),
    optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9),
    metrics   = ['mae']
)

maeScale = (temp.max() - temp.min()) * 10/100
print(maeScale)

class stopCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if (logs.get('mae') < maeScale and logs.get('val_mae') < maeScale):
            print(f'\nMAE and Validation MAE reach < 10% of the data scale ({maeScale})')
            # self.model.stop_training = True

stopTraining = stopCallback()

epoch = 10

history = model.fit(
    train_set,
    epochs          = epoch,
    validation_data = val_set,
    verbose         = 2,
    callbacks       = [stopTraining]
)

mae         = history.history['mae']
val_mae     = history.history['val_mae']

loss        = history.history['loss']
val_loss    = history.history['val_loss']

epoch_range = range(epoch)

plt.figure(figsize = (12, 4))
plt.subplot(1, 2, 1)
plt.plot(epoch_range, mae,     label='Training MAE')
plt.plot(epoch_range, val_mae, label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend(loc='lower right')

plt.subplot(1, 2, 2)
plt.plot(epoch_range, loss,     label='Training Loss')
plt.plot(epoch_range, val_loss, label='Valodation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')

plt.show()